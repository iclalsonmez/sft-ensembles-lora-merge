{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. KURULUM"
      ],
      "metadata": {
        "id": "ZSGsoTMDTiPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers datasets accelerate peft trl bitsandbytes huggingface_hub pyarrow pandas"
      ],
      "metadata": {
        "id": "W7JCNJd-bMzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. CONFIG + TOKEN + CSV YÜKLE + TEXT ÜRET"
      ],
      "metadata": {
        "id": "kUWiu7m_Tlkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login, hf_hub_download\n",
        "\n",
        "# config\n",
        "SMOKE_TEST = False  # True: hızlı test, False: gerçek run (2000/500)\n",
        "\n",
        "DATASET_ID = \"merve/tr-h4-norobots\"\n",
        "BASE_MODEL = \"ytu-ce-cosmos/tr-Qwen2.5-0.5B-SFT-v1\"\n",
        "\n",
        "TRAIN_N = 200 if SMOKE_TEST else 2000\n",
        "TEST_N  = 50  if SMOKE_TEST else 500\n",
        "MAX_LEN = 256 if SMOKE_TEST else 512\n",
        "\n",
        "OUT_DIR = \"/content/outputs_sft_ensembles_smoke\" if SMOKE_TEST else \"/content/outputs_sft_ensembles\"\n",
        "\n",
        "# HF TOKEN (colab secret: kolektif_hg)\n",
        "HF_TOKEN = \"\"\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = (userdata.get(\"kolektif_hg\") or \"\").strip()\n",
        "except Exception:\n",
        "    HF_TOKEN = (os.getenv(\"HF_TOKEN\") or \"\").strip()\n",
        "\n",
        "print(\"HF token var mı? ->\", bool(HF_TOKEN))\n",
        "if HF_TOKEN:\n",
        "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "    login(token=HF_TOKEN)\n",
        "\n",
        "# CSV dataset\n",
        "train_csv = hf_hub_download(DATASET_ID, repo_type=\"dataset\", filename=\"train_sft.csv\", token=HF_TOKEN if HF_TOKEN else None)\n",
        "test_csv  = hf_hub_download(DATASET_ID, repo_type=\"dataset\", filename=\"test_sft.csv\",  token=HF_TOKEN if HF_TOKEN else None)\n",
        "\n",
        "ds = load_dataset(\"csv\", data_files={\"train\": train_csv, \"test\": test_csv})\n",
        "train_raw, test_raw = ds[\"train\"], ds[\"test\"]\n",
        "print(\"Kolonlar:\", train_raw.column_names)\n",
        "\n",
        "def to_text(ex):\n",
        "    p = \"\" if ex.get(\"prompt\") is None else str(ex[\"prompt\"]).strip()\n",
        "    m = \"\" if ex.get(\"message\") is None else str(ex[\"message\"]).strip()\n",
        "    cat = ex.get(\"category\", \"UNKNOWN\")\n",
        "\n",
        "    if p and m:\n",
        "        text = f\"### Prompt:\\n{p}\\n\\n### Message:\\n{m}\"\n",
        "    elif m:\n",
        "        text = m\n",
        "    else:\n",
        "        text = p\n",
        "    return {\"text\": text, \"category\": cat}\n",
        "\n",
        "train_text = train_raw.map(to_text, remove_columns=train_raw.column_names)\n",
        "test_text  = test_raw.map(to_text,  remove_columns=test_raw.column_names)\n",
        "\n",
        "train_text = train_text.filter(lambda x: isinstance(x[\"text\"], str) and len(x[\"text\"].strip()) > 0)\n",
        "test_text  = test_text.filter(lambda x: isinstance(x[\"text\"], str) and len(x[\"text\"].strip()) > 0)\n",
        "\n",
        "print(\"train rows:\", len(train_text), \"test rows:\", len(test_text))\n",
        "print(\"\\nÖrnek:\\n\", train_text[0][\"text\"][:250])\n",
        "print(\"category:\", train_text[0][\"category\"])\n",
        "\n",
        "if len(train_text) < TRAIN_N:\n",
        "    raise RuntimeError(f\"Train {len(train_text)} satır. {TRAIN_N} için yetersiz.\")\n",
        "if len(test_text) < TEST_N:\n",
        "    raise RuntimeError(f\"Test {len(test_text)} satır. {TEST_N} için yetersiz.\")\n"
      ],
      "metadata": {
        "id": "o1r71De4FKLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. SUBSETLER (R1/R2 RANDOM + T1/T2 TOPIC) + TEST SET"
      ],
      "metadata": {
        "id": "72IzyvwyTweI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# test set (smoke: 50, full: 500) — shuffle ile sabitle\n",
        "test_set = test_text.shuffle(seed=123).select(range(TEST_N))\n",
        "\n",
        "# random subsetler\n",
        "R1 = train_text.shuffle(seed=1).select(range(TRAIN_N))\n",
        "R2 = train_text.shuffle(seed=2).select(range(TRAIN_N))\n",
        "\n",
        "# topic (kategori) split - dengeli\n",
        "cats = Counter(train_text[\"category\"])\n",
        "sorted_cats = [c for c,_ in cats.most_common()]\n",
        "\n",
        "g1, g2 = set(), set()\n",
        "s1 = s2 = 0\n",
        "for c in sorted_cats:\n",
        "    if s1 <= s2:\n",
        "        g1.add(c); s1 += cats[c]\n",
        "    else:\n",
        "        g2.add(c); s2 += cats[c]\n",
        "\n",
        "T1_pool = train_text.filter(lambda x: x[\"category\"] in g1)\n",
        "T2_pool = train_text.filter(lambda x: x[\"category\"] in g2)\n",
        "\n",
        "# random fallback (topic havuzu 2000/200’e yetmezse yine de proje aksın)\n",
        "if len(T1_pool) < TRAIN_N or len(T2_pool) < TRAIN_N:\n",
        "    print(\"Topic split yetmedi -> fallback random\")\n",
        "    T1 = train_text.shuffle(seed=3).select(range(TRAIN_N))\n",
        "    T2 = train_text.shuffle(seed=4).select(range(TRAIN_N))\n",
        "else:\n",
        "    T1 = T1_pool.shuffle(seed=3).select(range(TRAIN_N))\n",
        "    T2 = T2_pool.shuffle(seed=4).select(range(TRAIN_N))\n",
        "\n",
        "# full: smokeda sadece TRAIN_N kadar seç\n",
        "FULL = train_text.shuffle(seed=999).select(range(TRAIN_N)) if SMOKE_TEST else train_text\n",
        "\n",
        "print(\"Subset sizes:\", len(R1), len(R2), len(T1), len(T2), len(FULL), \"Test:\", len(test_set))\n",
        "print(\"Top categories:\", cats.most_common(10))\n"
      ],
      "metadata": {
        "id": "AXWue6jBFLii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. TOKENIZE (padding fix) + QLoRA LOADER + LoRA CONFIG (OTOMATİK target_modules)"
      ],
      "metadata": {
        "id": "NtlBLJL5T6eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, default_data_collator\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    out = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    # labels: pad tokenları -100\n",
        "    labels = []\n",
        "    for ids, am in zip(out[\"input_ids\"], out[\"attention_mask\"]):\n",
        "        labels.append([tok if mask == 1 else -100 for tok, mask in zip(ids, am)])\n",
        "    out[\"labels\"] = labels\n",
        "    return out\n",
        "\n",
        "def tok(ds_):\n",
        "    t = ds_.map(tokenize_batch, batched=True, remove_columns=ds_.column_names)\n",
        "    t.set_format(type=\"torch\")\n",
        "    return t\n",
        "\n",
        "test_tok = tok(test_set)\n",
        "R1_tok, R2_tok, T1_tok, T2_tok, FULL_tok = map(tok, [R1, R2, T1, T2, FULL])\n",
        "\n",
        "collator = default_data_collator\n",
        "print(\"Tokenized length:\", len(R1_tok[0][\"input_ids\"]))\n",
        "\n",
        "def load_qlora_base():\n",
        "    bnb_cfg = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL,\n",
        "        quantization_config=bnb_cfg,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    model.config.use_cache = False\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "    return model\n",
        "\n",
        "# LoRA target modül seçimi - farklı mimarilerde patlamasın diye otomatik\n",
        "def pick_target_modules(model):\n",
        "    leaf = set()\n",
        "    for n, _ in model.named_modules():\n",
        "        leaf.add(n.split(\".\")[-1])\n",
        "    for cand in ([\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"], [\"c_attn\",\"c_proj\"]):\n",
        "        ok = [c for c in cand if c in leaf]\n",
        "        if ok:\n",
        "            return ok\n",
        "    return [\"q_proj\",\"v_proj\"]\n",
        "\n",
        "_tmp = load_qlora_base()\n",
        "TARGET_MODULES = pick_target_modules(_tmp)\n",
        "del _tmp\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"LoRA target_modules:\", TARGET_MODULES)\n",
        "\n",
        "LORA_CFG = LoraConfig(\n",
        "    r=8 if SMOKE_TEST else 16,\n",
        "    lora_alpha=16 if SMOKE_TEST else 32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=TARGET_MODULES\n",
        ")\n"
      ],
      "metadata": {
        "id": "UMdaTN4kFNrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. EĞİTİM (hızlı smoke: max_steps=30) + KAYDET + log CSV"
      ],
      "metadata": {
        "id": "LelPfLxTUFFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from peft import get_peft_model\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "TRAIN_EPOCHS = 1\n",
        "TRAIN_BS = 2\n",
        "GRAD_ACCUM = 4 if SMOKE_TEST else 8\n",
        "LR = 2e-4\n",
        "MAX_STEPS = 30 if SMOKE_TEST else -1  # fullde epoch bazlı\n",
        "\n",
        "def train_lora(run_name, train_ds_tok):\n",
        "    out_dir = f\"{OUT_DIR}/{run_name}\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    model = load_qlora_base()\n",
        "    model = get_peft_model(model, LORA_CFG)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=out_dir,\n",
        "        num_train_epochs=TRAIN_EPOCHS,\n",
        "        max_steps=MAX_STEPS,  # smoke: kısa, full: -1\n",
        "\n",
        "        per_device_train_batch_size=TRAIN_BS,\n",
        "        gradient_accumulation_steps=GRAD_ACCUM,\n",
        "        learning_rate=LR,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        warmup_steps=10 if SMOKE_TEST else 50,\n",
        "\n",
        "        logging_steps=5 if SMOKE_TEST else 25,\n",
        "        report_to=[],  # boş - sürüm uyumu için\n",
        "\n",
        "        save_strategy=\"no\" if SMOKE_TEST else \"steps\",\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "\n",
        "        fp16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_pin_memory=False,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds_tok,\n",
        "        data_collator=collator,\n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "    # final adapter + tokenizer kaydet\n",
        "    model.save_pretrained(out_dir)\n",
        "    tokenizer.save_pretrained(out_dir)\n",
        "\n",
        "    # log_history -> csv\n",
        "    pd.DataFrame(trainer.state.log_history).to_csv(f\"{out_dir}/train_log.csv\", index=False)\n",
        "\n",
        "    del model, trainer\n",
        "    torch.cuda.empty_cache()\n",
        "    return out_dir\n",
        "\n",
        "runs = {}\n",
        "for name, ds_tok_ in [(\"R1\", R1_tok), (\"R2\", R2_tok), (\"T1\", T1_tok), (\"T2\", T2_tok), (\"FULL\", FULL_tok)]:\n",
        "    runs[name] = train_lora(name, ds_tok_)\n",
        "\n",
        "print(\"Eğitim bitti. Kayıt yeri:\", OUT_DIR)\n",
        "print(runs)\n"
      ],
      "metadata": {
        "id": "UUMHroflFPaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. EVAL (loss/ppl) + MERGE (R1+R2, T1+T2) + SONUÇ TABLOSU"
      ],
      "metadata": {
        "id": "lC03nBZzUOVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRECHECK\n",
        "\n",
        "# 5 step\n",
        "PRECHECK_STEPS = 5\n",
        "\n",
        "# MAX_STEPS - geçici\n",
        "_old_max_steps = MAX_STEPS\n",
        "MAX_STEPS = PRECHECK_STEPS\n",
        "print(\"Precheck: MAX_STEPS =\", MAX_STEPS)\n",
        "\n",
        "# sadece R1 ile deneme\n",
        "_ = train_lora(\"R1_preflight\", R1_tok)\n",
        "\n",
        "# geri al\n",
        "MAX_STEPS = _old_max_steps\n",
        "print(\"Precheck bitti. Full run'a geçebilirsin.\")\n"
      ],
      "metadata": {
        "id": "Gu6zSP_bT7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, pandas as pd\n",
        "from peft import PeftModel\n",
        "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM\n",
        "\n",
        "def eval_adapter(adapter_dir):\n",
        "    model = load_qlora_base()\n",
        "    model = PeftModel.from_pretrained(model, adapter_dir)\n",
        "    model.eval()\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"{OUT_DIR}/_tmp_eval\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        fp16=True,\n",
        "        report_to=[],\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_pin_memory=False,\n",
        "    )\n",
        "    trainer = Trainer(model=model, args=args, eval_dataset=test_tok, data_collator=collator)\n",
        "    metrics = trainer.evaluate()\n",
        "    loss = float(metrics[\"eval_loss\"])\n",
        "    ppl = math.exp(loss) if loss < 20 else float(\"inf\")\n",
        "\n",
        "    del model, trainer\n",
        "    torch.cuda.empty_cache()\n",
        "    return {\"eval_loss\": loss, \"ppl\": ppl}\n",
        "\n",
        "# MERGE: LoRA ağırlıklarını ortalama\n",
        "def _get_adapter_sd(peft_model):\n",
        "    try:\n",
        "        from peft.utils import get_peft_model_state_dict\n",
        "        return get_peft_model_state_dict(peft_model)\n",
        "    except Exception:\n",
        "        sd = peft_model.state_dict()\n",
        "        return {k:v for k,v in sd.items() if \"lora_\" in k}\n",
        "\n",
        "def _set_adapter_sd(peft_model, sd):\n",
        "    try:\n",
        "        from peft.utils import set_peft_model_state_dict\n",
        "        set_peft_model_state_dict(peft_model, sd)\n",
        "    except Exception:\n",
        "        peft_model.load_state_dict(sd, strict=False)\n",
        "\n",
        "def merge_adapters_average(adapter_a, adapter_b, out_dir, w_a=0.5, w_b=0.5):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    baseA = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=torch.float16, device_map=\"cpu\", trust_remote_code=True)\n",
        "    mA = PeftModel.from_pretrained(baseA, adapter_a, is_trainable=False)\n",
        "    sdA = _get_adapter_sd(mA)\n",
        "\n",
        "    baseB = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=torch.float16, device_map=\"cpu\", trust_remote_code=True)\n",
        "    mB = PeftModel.from_pretrained(baseB, adapter_b, is_trainable=False)\n",
        "    sdB = _get_adapter_sd(mB)\n",
        "\n",
        "    keys = sorted(set(sdA.keys()) | set(sdB.keys()))\n",
        "    merged = {}\n",
        "    for k in keys:\n",
        "        if k in sdA and k in sdB:\n",
        "            merged[k] = (w_a * sdA[k].float() + w_b * sdB[k].float()).half()\n",
        "        elif k in sdA:\n",
        "            merged[k] = sdA[k]\n",
        "        else:\n",
        "            merged[k] = sdB[k]\n",
        "\n",
        "    baseM = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=torch.float16, device_map=\"cpu\", trust_remote_code=True)\n",
        "    mM = PeftModel.from_pretrained(baseM, adapter_a, is_trainable=False)\n",
        "    _set_adapter_sd(mM, merged)\n",
        "\n",
        "    mM.save_pretrained(out_dir)\n",
        "    tokenizer.save_pretrained(out_dir)\n",
        "    return out_dir\n",
        "\n",
        "merged_R = merge_adapters_average(runs[\"R1\"], runs[\"R2\"], f\"{OUT_DIR}/MERGE_R\")\n",
        "merged_T = merge_adapters_average(runs[\"T1\"], runs[\"T2\"], f\"{OUT_DIR}/MERGE_T\")\n",
        "\n",
        "results = {k: eval_adapter(v) for k,v in runs.items()}\n",
        "results[\"MERGE_R\"] = eval_adapter(merged_R)\n",
        "results[\"MERGE_T\"] = eval_adapter(merged_T)\n",
        "\n",
        "df = pd.DataFrame(results).T.sort_values(\"eval_loss\")\n",
        "print(df)\n",
        "df.to_csv(f\"{OUT_DIR}/results_summary.csv\", index=True)\n",
        "\n",
        "print(\"\\nÖzet kaydedildi:\", f\"{OUT_DIR}/results_summary.csv\")\n"
      ],
      "metadata": {
        "id": "0jx6-1RkFRRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. ZIP İNDİR"
      ],
      "metadata": {
        "id": "67tmgmrEUcOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "zip_path = shutil.make_archive(OUT_DIR, 'zip', OUT_DIR)\n",
        "print(\"ZIP:\", zip_path)\n"
      ],
      "metadata": {
        "id": "ptNzYju5FTJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. BEST ADAPTER YÜKLE -> HF"
      ],
      "metadata": {
        "id": "O_QQo19VUiTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUSH_TO_HF = False  # True - upload eder\n",
        "HF_REPO = \"iclallalala/sft-ensembles-best-adapter\"\n",
        "\n",
        "if PUSH_TO_HF:\n",
        "    from huggingface_hub import create_repo, upload_folder\n",
        "    if not HF_TOKEN:\n",
        "        raise RuntimeError(\"HF_TOKEN yok.\")\n",
        "    create_repo(HF_REPO, private=True, exist_ok=True, token=HF_TOKEN)\n",
        "\n",
        "    # en iyi model (results_summary.csv'den)\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(f\"{OUT_DIR}/results_summary.csv\")\n",
        "    best_name = df.sort_values(\"eval_loss\").iloc[0][\"Unnamed: 0\"]\n",
        "    best_dir = f\"{OUT_DIR}/{best_name}\"\n",
        "    print(\"Best:\", best_name, best_dir)\n",
        "\n",
        "    upload_folder(\n",
        "        repo_id=HF_REPO,\n",
        "        folder_path=best_dir,\n",
        "        repo_type=\"model\",\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "    print(\"HF’ye yüklendi:\", HF_REPO)\n"
      ],
      "metadata": {
        "id": "DY7TT53UFVOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. GÖRSELLER"
      ],
      "metadata": {
        "id": "2SWK-1D6qOzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- güvenlik kontrolü\n",
        "assert \"OUT_DIR\" in globals(), \"OUT_DIR tanımlı değil.\"\n",
        "FIG_DIR = f\"{OUT_DIR}/figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "res_path = f\"{OUT_DIR}/results_summary.csv\"\n",
        "assert os.path.exists(res_path), f\"{res_path} yok. Önce eval sonuçlarını üret.\"\n",
        "\n",
        "# --- results oku\n",
        "df = pd.read_csv(res_path)\n",
        "if \"Unnamed: 0\" in df.columns:\n",
        "    df = df.rename(columns={\"Unnamed: 0\":\"run\"})\n",
        "else:\n",
        "    df = df.rename(columns={df.columns[0]:\"run\"})\n",
        "df = df.sort_values(\"eval_loss\", ascending=True)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "dVIIHGX-por0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) eval_loss bar\n",
        "plt.figure()\n",
        "plt.bar(df[\"run\"], df[\"eval_loss\"])\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"eval_loss (lower is better)\")\n",
        "plt.title(\"Test Performance (eval_loss)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/eval_loss_bar.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.05)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8C68UvJIp8WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) ppl bar\n",
        "plt.figure()\n",
        "plt.bar(df[\"run\"], df[\"ppl\"])\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"perplexity (lower is better)\")\n",
        "plt.title(\"Test Performance (perplexity)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/ppl_bar.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.05)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-vwLub8p-y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) results table\n",
        "plt.figure()\n",
        "plt.axis(\"off\")\n",
        "table_df = df[[\"run\",\"eval_loss\",\"ppl\"]].copy()\n",
        "table_df[\"eval_loss\"] = table_df[\"eval_loss\"].map(lambda x: f\"{x:.4f}\")\n",
        "table_df[\"ppl\"] = table_df[\"ppl\"].map(lambda x: f\"{x:.3f}\")\n",
        "tbl = plt.table(cellText=table_df.values, colLabels=table_df.columns, loc=\"center\")\n",
        "tbl.auto_set_font_size(False)\n",
        "tbl.set_fontsize(10)\n",
        "tbl.scale(1, 1.3)\n",
        "plt.title(\"Results Summary (Test Set)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/results_table.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.05)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KYcwj8R8qAvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) train loss curves\n",
        "log_files = glob.glob(f\"{OUT_DIR}/*/train_log.csv\")\n",
        "plt.figure()\n",
        "any_plotted = False\n",
        "xlabel = \"step\"\n",
        "for lf in log_files:\n",
        "    run = lf.split(\"/\")[-2]\n",
        "    d = pd.read_csv(lf)\n",
        "    if \"loss\" not in d.columns:\n",
        "        continue\n",
        "    d2 = d.dropna(subset=[\"loss\"])\n",
        "    if d2.empty:\n",
        "        continue\n",
        "\n",
        "    if \"step\" in d2.columns and d2[\"step\"].notna().any():\n",
        "        x = d2[\"step\"]; xlabel = \"step\"\n",
        "    elif \"epoch\" in d2.columns and d2[\"epoch\"].notna().any():\n",
        "        x = d2[\"epoch\"]; xlabel = \"epoch\"\n",
        "    else:\n",
        "        x = range(len(d2)); xlabel = \"log_index\"\n",
        "\n",
        "    plt.plot(x, d2[\"loss\"], label=run)\n",
        "    any_plotted = True\n",
        "\n",
        "if any_plotted:\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(\"train loss\")\n",
        "    plt.title(\"Training Loss Curves\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{FIG_DIR}/train_loss_curves.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.05)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Loss için uygun log bulunamadı (train_log.csv kontrol et).\")"
      ],
      "metadata": {
        "id": "g5qt8e4YqCvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) pipeline diagram\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "FIG_DIR = f\"{OUT_DIR}/figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 3.6))\n",
        "ax.axis(\"off\")\n",
        "\n",
        "def box(text, x, y, fs=11):\n",
        "    ax.text(x, y, text, ha=\"center\", va=\"center\", fontsize=fs,\n",
        "            bbox=dict(boxstyle=\"round,pad=0.5\"))\n",
        "\n",
        "def arrow(x1,y1,x2,y2):\n",
        "    ax.annotate(\"\", xy=(x2,y2), xytext=(x1,y1),\n",
        "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
        "                arrowprops=dict(arrowstyle=\"->\", lw=1.8))\n",
        "\n",
        "# kutular\n",
        "box(\"Dataset\\n(train_sft / test_sft)\", 0.18, 0.80)\n",
        "box(\"Subset oluşturma\\nR1,R2 (random)\\nT1,T2 (topic)\\nFULL (all train)\", 0.18, 0.52)\n",
        "box(\"SFT Training\\n(QLoRA + LoRA)\", 0.18, 0.22)\n",
        "\n",
        "box(\"LoRA Merge\\nMERGE_R = avg(R1,R2)\\nMERGE_T = avg(T1,T2)\", 0.78, 0.52, fs=10.5)\n",
        "box(\"Test Eval\\n(eval_loss, ppl)\\n(500 samples)\", 0.78, 0.22)\n",
        "\n",
        "# oklar (daha hizalı)\n",
        "arrow(0.18, 0.72, 0.18, 0.60)   # Dataset -> Subset\n",
        "arrow(0.18, 0.42, 0.18, 0.30)   # Subset -> Training\n",
        "\n",
        "# Training kutusunun sağından çıkan iki ok\n",
        "arrow(0.30, 0.22, 0.66, 0.22)   # Training -> Eval\n",
        "arrow(0.30, 0.26, 0.66, 0.50)   # Training -> Merge (biraz yukarıdan)\n",
        "\n",
        "arrow(0.78, 0.42, 0.78, 0.30)   # Merge -> Eval\n",
        "\n",
        "ax.set_xlim(0,1)\n",
        "ax.set_ylim(0,1)\n",
        "\n",
        "png_path = f\"{FIG_DIR}/pipeline_diagram.png\"\n",
        "pdf_path = f\"{FIG_DIR}/pipeline_diagram.pdf\"\n",
        "plt.savefig(png_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.08)\n",
        "plt.savefig(pdf_path, bbox_inches=\"tight\", pad_inches=0.08)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\", png_path)\n",
        "print(\"Saved:\", pdf_path)"
      ],
      "metadata": {
        "id": "P7Bue37FqE6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "print(\"OUT_DIR =\", OUT_DIR)\n",
        "print(\"Alt klasörler:\", [p.split(\"/\")[-1] for p in glob.glob(f\"{OUT_DIR}/*\") if os.path.isdir(p)])\n",
        "\n",
        "# her run için temel dosyalar var mı?\n",
        "for run in [\"R1\",\"R2\",\"T1\",\"T2\",\"FULL\",\"MERGE_R\",\"MERGE_T\"]:\n",
        "    p = f\"{OUT_DIR}/{run}\"\n",
        "    if os.path.isdir(p):\n",
        "        print(run, \"->\", \"OK\",\n",
        "              \"| files:\", [os.path.basename(x) for x in glob.glob(p+\"/*\")][:8])\n",
        "    else:\n",
        "        print(run, \"-> YOK\")\n"
      ],
      "metadata": {
        "id": "bxkKIpG4juFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, pandas as pd\n",
        "from peft import PeftModel\n",
        "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM\n",
        "\n",
        "# eval\n",
        "def eval_adapter(adapter_dir):\n",
        "    model = load_qlora_base()\n",
        "    model = PeftModel.from_pretrained(model, adapter_dir)\n",
        "    model.eval()\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"{OUT_DIR}/_tmp_eval\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        fp16=True,\n",
        "        report_to=[],\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_pin_memory=False,\n",
        "    )\n",
        "    trainer = Trainer(model=model, args=args, eval_dataset=test_tok, data_collator=collator)\n",
        "    metrics = trainer.evaluate()\n",
        "    loss = float(metrics[\"eval_loss\"])\n",
        "    ppl = math.exp(loss) if loss < 20 else float(\"inf\")\n",
        "    del model, trainer\n",
        "    import torch; torch.cuda.empty_cache()\n",
        "    return {\"eval_loss\": loss, \"ppl\": ppl}\n",
        "\n",
        "# merge (average LoRA)\n",
        "def _get_adapter_sd(peft_model):\n",
        "    try:\n",
        "        from peft.utils import get_peft_model_state_dict\n",
        "        return get_peft_model_state_dict(peft_model)\n",
        "    except Exception:\n",
        "        sd = peft_model.state_dict()\n",
        "        return {k:v for k,v in sd.items() if \"lora_\" in k}\n",
        "\n",
        "def _set_adapter_sd(peft_model, sd):\n",
        "    try:\n",
        "        from peft.utils import set_peft_model_state_dict\n",
        "        set_peft_model_state_dict(peft_model, sd)\n",
        "    except Exception:\n",
        "        peft_model.load_state_dict(sd, strict=False)\n",
        "\n",
        "def merge_adapters_average(adapter_a, adapter_b, out_dir, w_a=0.5, w_b=0.5):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    baseA = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=\"auto\", device_map=\"cpu\", trust_remote_code=True)\n",
        "    mA = PeftModel.from_pretrained(baseA, adapter_a, is_trainable=False)\n",
        "    sdA = _get_adapter_sd(mA)\n",
        "\n",
        "    baseB = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=\"auto\", device_map=\"cpu\", trust_remote_code=True)\n",
        "    mB = PeftModel.from_pretrained(baseB, adapter_b, is_trainable=False)\n",
        "    sdB = _get_adapter_sd(mB)\n",
        "\n",
        "    keys = sorted(set(sdA.keys()) | set(sdB.keys()))\n",
        "    merged = {}\n",
        "    for k in keys:\n",
        "        if k in sdA and k in sdB:\n",
        "            merged[k] = (w_a * sdA[k].float() + w_b * sdB[k].float()).half()\n",
        "        elif k in sdA:\n",
        "            merged[k] = sdA[k]\n",
        "        else:\n",
        "            merged[k] = sdB[k]\n",
        "\n",
        "    baseM = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=\"auto\", device_map=\"cpu\", trust_remote_code=True)\n",
        "    mM = PeftModel.from_pretrained(baseM, adapter_a, is_trainable=False)\n",
        "    _set_adapter_sd(mM, merged)\n",
        "\n",
        "    mM.save_pretrained(out_dir)\n",
        "    tokenizer.save_pretrained(out_dir)\n",
        "    return out_dir\n",
        "\n",
        "# merge klasörleri\n",
        "merged_R = merge_adapters_average(f\"{OUT_DIR}/R1\", f\"{OUT_DIR}/R2\", f\"{OUT_DIR}/MERGE_R\")\n",
        "merged_T = merge_adapters_average(f\"{OUT_DIR}/T1\", f\"{OUT_DIR}/T2\", f\"{OUT_DIR}/MERGE_T\")\n",
        "\n",
        "# eval all\n",
        "runs_dirs = {\n",
        "  \"R1\": f\"{OUT_DIR}/R1\",\n",
        "  \"R2\": f\"{OUT_DIR}/R2\",\n",
        "  \"T1\": f\"{OUT_DIR}/T1\",\n",
        "  \"T2\": f\"{OUT_DIR}/T2\",\n",
        "  \"FULL\": f\"{OUT_DIR}/FULL\",\n",
        "  \"MERGE_R\": merged_R,\n",
        "  \"MERGE_T\": merged_T\n",
        "}\n",
        "\n",
        "results = {k: eval_adapter(v) for k,v in runs_dirs.items()}\n",
        "df = pd.DataFrame(results).T.sort_values(\"eval_loss\")\n",
        "display(df)\n",
        "\n",
        "df.to_csv(f\"{OUT_DIR}/results_summary.csv\", index=True)\n",
        "print(\"Kaydedildi:\", f\"{OUT_DIR}/results_summary.csv\")\n"
      ],
      "metadata": {
        "id": "FguskNO1jurB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive(OUT_DIR, 'zip', OUT_DIR)\n",
        "print(\"ZIP:\", zip_path)\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "akNZfk51j7AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "fig_zip = shutil.make_archive(f\"{OUT_DIR}/figures\", 'zip', f\"{OUT_DIR}/figures\")\n",
        "files.download(fig_zip)"
      ],
      "metadata": {
        "id": "9zWRjZu4lHn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, torch\n",
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "\n",
        "base_fp16 = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "base_fp16.config.use_cache = False\n",
        "base_fp16.config.pad_token_id = tokenizer.pad_token_id\n",
        "base_fp16.eval()\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=f\"{OUT_DIR}/_tmp_eval_base\",\n",
        "    per_device_eval_batch_size=4,\n",
        "    fp16=True,\n",
        "    report_to=[],\n",
        "    remove_unused_columns=False,\n",
        "    dataloader_pin_memory=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_fp16,\n",
        "    args=args,\n",
        "    eval_dataset=test_tok,\n",
        "    data_collator=collator\n",
        ")\n",
        "\n",
        "m = trainer.evaluate()\n",
        "base_loss = float(m[\"eval_loss\"])\n",
        "print(\"BASE eval_loss:\", base_loss, \"ppl:\", math.exp(base_loss))"
      ],
      "metadata": {
        "id": "niXQGFh5lKpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overlap kontrol\n",
        "print(\"T1 unique categories:\", len(set(T1[\"category\"])))\n",
        "print(\"T2 unique categories:\", len(set(T2[\"category\"])))\n",
        "print(\"Overlap categories:\", len(set(T1[\"category\"]) & set(T2[\"category\"])))\n"
      ],
      "metadata": {
        "id": "RAhnEIB1lO_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmPYkZbH_gUS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
